{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1_Student_code Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XYang20/Learning-Git-Hub/blob/master/Project_1_Student_code_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz_KGiHXU_j9"
      },
      "source": [
        "#Student Name: Xiaoping Yang\n",
        "#ECE 595 Machine Learning II\n",
        "#Project 1: CLDNN - Student Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GT54CknVKs0"
      },
      "source": [
        "#Import necessary packages\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Reshape, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as cPickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCZj_eY9Vi-R"
      },
      "source": [
        "#Part 0: Importing and normalizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ass5riibVnL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c42d061-b83b-4231-8bc6-fcb24f0cb8d7"
      },
      "source": [
        "#Import dataset and normalize to [0,1]\n",
        "#Has shape (num_samples, 28, 28)\n",
        "(data_train, labels_train), (data_test, labels_test) = fashion_mnist.load_data()\n",
        "data_train = data_train/255.0\n",
        "data_test = data_test/255.0\n",
        "data_train = data_train.reshape(60000, 28, 28, 1)\n",
        "data_test = data_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "#Create labels as one-hot vectors\n",
        "#labels_train and labels_test have shapes (60000, 10) and (10000 10,) respectively\n",
        "labels_train = keras.utils.np_utils.to_categorical(labels_train, num_classes=10)\n",
        "labels_test = keras.utils.np_utils.to_categorical(labels_test, num_classes=10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "372Co-fUV1fD"
      },
      "source": [
        "#Part 1: Plotting cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJJ0b7Z2V5h4"
      },
      "source": [
        "#Show cross-entropy loss function\n",
        "\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT\n",
        "#CLDNN - Example Code\n",
        "num_samples=5000\n",
        "n=10\n",
        "num_channels=3\n",
        "num_classes=12\n",
        "#Create 5000 samples of random training data\n",
        "data_train=np.random.rand(5000,n,n,num_channels)\n",
        "#Create 1000 samples of random testing data\n",
        "data_test=np.random.rand(1000,n,n,num_channels)\n",
        "#Assign labels to training and testing data\n",
        "labels_train=np.random.randint(low=0,high=11,size=(5000,))\n",
        "labels_test=np.random.randint(low=0,high=11,size=(1000,))\n",
        "#Transform labels to one-hot vectors\n",
        "labels_train=keras.utils.np_utils.to_categorical(labels_train,num_classes=num_classes)\n",
        "labels_test=keras.utils.np_utils.to_categorical(labels_test,num_classes=num_classes)\n",
        "#Create a function that returns an initialized cnn model\n",
        "def cnn():\n",
        "  #Sequential allows model to be built layer by layer\n",
        "  model=Sequential()\n",
        "  #Bild a 2D Convolutional layer with 64 feature maps and a 8x8 filter\n",
        "  #first layer requires a specified input shape\n",
        "  model.add(Conv2(64,(8,8),activation='sigmoid',input_shape=(n,n,num_channels)))\n",
        "  #Randomly freezes 25% of weights in previous layer to prevent overfitting\n",
        "  model.add(Dropout(0.25))\n",
        "  #Add a 2x2 MaxPooling layer\n",
        "  model.add(MaxPooling2D(pool_size(2,2),strides=None,padding='valid',data_format=None))\n",
        "  #Flatten data for input into Dense layers\n",
        "  model.add(Flatten())\n",
        "  #Add Dense layer with 256 perceptrons\n",
        "  model.add(Dense(256,activation=\"relu\",kernel_initializer=\"normal\"))\n",
        "  #Output layer with num_classes perceptrons\n",
        "  model.add(Dense(num_classes,activation=\"softmax\"))\n",
        "  return model\n",
        "\n",
        "  #Create graph of model\n",
        "  cnn_model=cnn()\n",
        "  #Compile the model\n",
        "  cnn_model.compile(loss='mean_squared_error',optimizer='RMSprop',metrics=['accuracy'])\n",
        "  #Train the model\n",
        "  cnn_model_mdata=cnn_model.fit(data_train,labels_train,validation_data=(data_test,labels_test),epochs=100,batch_size=1024,shuffle=True)\n",
        "  #Evaluate the accuracy of the model on the testing set\n",
        "  scores=cnn_model.evaluate(data_test,labels_test)\n",
        "  #Print the accuracy of the testing set\n",
        "  print(\"Accuracy:%.2f%%\" %(scores[1]*100))\n",
        "  #Plot the accuracy as epoch\n",
        "  plt.plot(cnn_model_mdata.history['accuracy'])\n",
        "  plt.plot(cnn_model_mdata.history['val_accuracy'])\n",
        "  plt.title('CNN Accuracy vs. Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train','test'],loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  #Plot the loss vs epoch\n",
        "  plt.plot(cnn_model_mdata.history['loss'])\n",
        "  plt.plot(cnn_model_mdata.history['val_loss'])\n",
        "  plt.title('CNN Loss vs. Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train','test'],loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsGXDCdf4-zc"
      },
      "source": [
        "Answer the following questions:\n",
        "\n",
        "\n",
        "1.   How is the the negative log-likelihood of p affected when p is small? How about when p is large?\n",
        "\n",
        "  ANS: \n",
        "\n",
        "2.   Why does the behavior of the negative log-likelihood function make it a good objective function for a minimization problem specifically when the output can be interpreted as a probability space?\n",
        "\n",
        "  ANS: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uF9StudWHXQ"
      },
      "source": [
        "#Part 2: Overfit CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMko5jJkWJLp"
      },
      "source": [
        "#Create and train model architecture\n",
        "def CNN_overfit():\n",
        "    #Easiest way to build model in Keras is using Squential. It allows models to \n",
        "    #be built layer by layer as we will do here\n",
        "    model = Sequential()\n",
        "    \n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE\n",
        "\n",
        "    return model\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_overfit = CNN_overfit()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqT3SVgAWVtT"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKnbIsWgZDaG"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWK1Tv117Gol"
      },
      "source": [
        "Answer the following questions: \n",
        "\n",
        "\n",
        "\n",
        "1.   What does the loss of the training set go to? \n",
        "\n",
        "  ANS: \n",
        "\n",
        "2.   What does the loss of the testing set go to? \n",
        "\n",
        "  ANS: \n",
        "  \n",
        "3.   What is the reason for the discrepancy between the training and testing set loss? \n",
        "\n",
        "  ANS:\n",
        "\n",
        "4.   Explain why the accuracy of the testing set, after training, differs so much from the testing set regardless of achieving high training accuracy. Name two ways to avoid this. \n",
        "\n",
        "  ANS: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QhQ4ZXGcZJf"
      },
      "source": [
        "#Part 3: Dropout on input layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS3EfyKCcbtB"
      },
      "source": [
        "#Create and train model architecture\n",
        "def CNN_dropout_in():\n",
        "    model = Sequential()\n",
        "\n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE\n",
        "    \n",
        "    return model\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_dropout_in = CNN_dropout_in()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5aoDt8Eck9e"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEVvXC1cyEY"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FthASFFA_Mnv"
      },
      "source": [
        "Answer the following questions: \n",
        "\n",
        "\n",
        "\n",
        "1.   What does the loss of the training set go to? \n",
        "\n",
        "  ANS: \n",
        "  \n",
        "2.   What does the loss of the testing set go to? \n",
        "\n",
        "  ANS: \n",
        "\n",
        "3.   Why is the loss of the training set so different from the loss of the testing set regardless of using dropout? \n",
        "\n",
        "  ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P2qmzu_c91_"
      },
      "source": [
        "#Part 4-I: Dropout on Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhRZhmwdAOk"
      },
      "source": [
        "#Create and train model architecture\n",
        "def CNN_dropout_hidden():\n",
        "    model = Sequential()\n",
        "\n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE\n",
        "    \n",
        "    return model\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_dropout_hidden = CNN_dropout_hidden()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmAK5EDqdH-Y"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsYl9g3tdK5o"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mmDCmQvAsuS"
      },
      "source": [
        "Answer the following questions:\n",
        "\n",
        "\n",
        "\n",
        "1.   What does the loss of the training set go to? \n",
        "\n",
        "  ANS: \n",
        "  \n",
        "2.   What does the loss of the testing set go to? \n",
        "\n",
        "  ANS: \n",
        "\n",
        "3.   Why was using dropout more effective here in comparison to the architecture in Part 3? \n",
        "\n",
        "  ANS: \n",
        "  \n",
        "4.   What is the difference in accuracy, after training, between the training and testing set? Is the model a good fit for the data? \n",
        "\n",
        "  ANS: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1QJu0Y4dUKj"
      },
      "source": [
        "#Part 4-II [Sub-Question 5]: Dropout on Input and Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we62eVHLde0f"
      },
      "source": [
        "#Create and train model architecture\n",
        "def CNN_dropout_both():\n",
        "\n",
        "    #Easiest way to build model in Keras is using Squential. It allows model to be build layer by layer as we will do here\n",
        "    model = Sequential()\n",
        "\n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_dropout_both = CNN_dropout_both()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqpDuw-mdlcJ"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmz-pmardo6J"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ985f21De-W"
      },
      "source": [
        "Answer the following questions: \n",
        "\n",
        "1.   What does the loss of the training set go to? \n",
        "\n",
        "  ANS: \n",
        "  \n",
        "2.   What does the loss of the testing set go to? \n",
        "\n",
        "  ANS:\n",
        "  \n",
        "3.   What is the difference in accuracy, after training, between the training and testing set?  \n",
        "\n",
        "  ANS: \n",
        "\n",
        "4.   Compare results in 4 with results in 5. Comment on robustness and accuracy.\n",
        "\n",
        "  ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C60C05uR7KFF"
      },
      "source": [
        "#Part 5 : Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wja8Smy27XlL"
      },
      "source": [
        "#Create and train model architecture\n",
        "def CNN_dropout_both_act():\n",
        "\n",
        "    #Easiest way to build model in Keras is using Squential. It allows model to be build layer by layer as we will do here\n",
        "    model = Sequential()\n",
        "\n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE   # use 'sigmoid' for point 1 and use 'tanh' for point 2\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_dropout_both_act = CNN_dropout_both_act()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF2KktB47cdN"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipO8J6a7gmz"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ_QzwdN74Kj"
      },
      "source": [
        "Answer the following questions: \n",
        "\n",
        "1-c.   Compare the above results with softmax results (with point 5 results of Part 4-II)\n",
        "\n",
        "  ANS:\n",
        "  \n",
        "2-a.   Does ‘tanh’ as output activation work with Cross-entropy loss?\n",
        "\n",
        "  ANS:\n",
        "\n",
        "2-b.   Give a reason why tanh is not recommended with cross entropy loss?\n",
        "\n",
        "  ANS: \n",
        "\n",
        "2-c.   Give a reason why sigmoid does not cause problem as tanh with Cross entropy loss?\n",
        "\n",
        "  ANS: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3M_r3Sd2oI"
      },
      "source": [
        "#Part 6: Creating a CLDNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enhoZBkdnhcz"
      },
      "source": [
        "Run the code in the block below 'as is.' After executing, the high SNR RadioML training and testing data will be stored in the arrays X_train and X_test, respectively. Their respective one-hot labels will be stored in Y_train and Y_test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFbDIRH_Nn2C"
      },
      "source": [
        "#Download RML 2016.10b dataset and untar file\n",
        "!wget http://opendata.deepsig.io/datasets/2016.10/RML2016.10b.tar.bz2\n",
        "!tar -xvjf RML2016.10b.tar.bz2\n",
        "\n",
        "#Extract high SNR data and obtain their corresponding lables \n",
        "Xd = cPickle.load(open(\"RML2016.10b.dat\",'rb'))\n",
        "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
        "X = []\n",
        "lbl = []\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        if snr > 0:\n",
        "            X.append(Xd[(mod,snr)])\n",
        "            for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
        "X = np.vstack(X)\n",
        "\n",
        "np.random.seed(2016)\n",
        "n_examples = X.shape[0]\n",
        "n_train = n_examples * 0.8\n",
        "n_train = int(n_train)\n",
        "train_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\n",
        "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
        "X_train = X[train_idx]\n",
        "X_test =  X[test_idx]\n",
        "def to_onehot(yy):\n",
        "    yy1 = np.zeros([len(yy), max(yy)+1])\n",
        "    yy1[np.arange(len(yy)),yy] = 1\n",
        "    return yy1\n",
        "Y_train = to_onehot(map(lambda x: mods.index(lbl[x][0]), train_idx))\n",
        "Y_test = to_onehot(map(lambda x: mods.index(lbl[x][0]), test_idx))\n",
        "\n",
        "#Re-shape data to appropriate dimensions \n",
        "X_train = X_train.reshape(432000, 2, 128, 1)\n",
        "X_test = X_test.reshape(108000, 2, 128, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjIxEpGgsrY"
      },
      "source": [
        "#Create and train model architecture\n",
        "def cldnn():\n",
        "    model = Sequential()\n",
        "    \n",
        "    #FILL THIS IN WITH MODEL ARCHITECTURE\n",
        "    \n",
        "    return model\n",
        "\n",
        "#Create instance of CNN model graph\n",
        "CNN_overfit = CNN_overfit()\n",
        "\n",
        "#Compile model using an appropriate loss and optimizer algorithm\n",
        "#FILL THIS IN\n",
        "\n",
        "#Train the model and assign training meta-data to a variable\n",
        "#FILL THIS IN\n",
        "\n",
        "#Print accuracy of model on testing set after training \n",
        "#FILL THIS IN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmeOrC3igzR1"
      },
      "source": [
        "#Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wdPg2GJg28R"
      },
      "source": [
        "#Plot loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOeEmHptEwwU"
      },
      "source": [
        "Answer the following questions: \n",
        "\n",
        "\n",
        "\n",
        "1.   Is this model a good fit for the data?  \n",
        "\n",
        "  ANS: \n",
        "\n",
        "2.   Give two ways to improve the robustness of the model.\n",
        "\n",
        "  ANS: "
      ]
    }
  ]
}